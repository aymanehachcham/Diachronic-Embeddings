{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "SENSES_FILE = 'embeddings_for_senses.json'\n",
    "EXAMPLES_FILE = 'embeddings_1980.json'\n",
    "WORDS = 'polysemous.txt'\n",
    "\n",
    "class LoadingEmbeddings():\n",
    "\n",
    "    @classmethod\n",
    "    def load_files(\n",
    "            cls,\n",
    "            root_dir:str,\n",
    "            sense_embeddings_file: str,\n",
    "            example_embeddings_file: str,\n",
    "        ):\n",
    "\n",
    "        if (os.path.exists(os.path.join(root_dir, sense_embeddings_file))) \\\n",
    "            and (os.path.exists(os.path.join(root_dir, sense_embeddings_file))):\n",
    "            cls.sense_file = os.path.join(root_dir, sense_embeddings_file)\n",
    "            cls.examples_file = os.path.join(root_dir, example_embeddings_file)\n",
    "\n",
    "        logging.basicConfig(level=logging.NOTSET)\n",
    "        ex, sens = cls._load_files()\n",
    "        return ex, sens\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_files():\n",
    "        with open(os.path.join('../embeddings', EXAMPLES_FILE), 'r') as f:\n",
    "            logging.info('{} Loading File {} {}'.format('-'*10, f.name, '-'*10))\n",
    "            example_embeds = json.load(f)\n",
    "\n",
    "        with open(os.path.join('../embeddings', SENSES_FILE), 'r') as f:\n",
    "            logging.info('{} Loading File {} {}'.format('-'*10, f.name, '-'*10))\n",
    "            senses_embeds = json.load(f)\n",
    "\n",
    "        return example_embeds, senses_embeds\n",
    "\n",
    "\n",
    "class Similarities():\n",
    "    def __init__(\n",
    "            self,\n",
    "        ):\n",
    "\n",
    "        self.embeddings_examples, self.embeddings_senses = LoadingEmbeddings.load_files(\n",
    "            root_dir='../embeddings',\n",
    "            sense_embeddings_file=SENSES_FILE,\n",
    "            example_embeddings_file=EXAMPLES_FILE\n",
    "        )\n",
    "        self.word_sense_proportions = {}\n",
    "\n",
    "    def _search_word_sense(self, word:str):\n",
    "        for w in self.embeddings_senses:\n",
    "            if w[0]['word'] == word:\n",
    "                yield w\n",
    "\n",
    "    def _cos_sim(self, vect_a:np.array, vect_b:np.array):\n",
    "        return (vect_a @ vect_b)/(norm(vect_a) * norm(vect_b))\n",
    "\n",
    "    def __call__(self, word:str):\n",
    "        from collections import Counter\n",
    "        examples = np.array(self.embeddings_examples[word]['embeddings'])\n",
    "        try:\n",
    "            senses = next(self._search_word_sense(word))\n",
    "        except StopIteration:\n",
    "            raise ValueError(\n",
    "                'Word not in list'\n",
    "            )\n",
    "\n",
    "        all_sims = []\n",
    "        for embed in examples:\n",
    "            s_argmax =  np.argmax(list(self._cos_sim(sens['embedding'], embed) for sens in senses))\n",
    "            all_sims.append(senses[s_argmax]['sense'])\n",
    "\n",
    "        self.word_sense_proportions['word'] = word\n",
    "        self.word_sense_proportions['props'] = list(map(lambda x: x[1]/len(all_sims), Counter(all_sims).most_common()))\n",
    "\n",
    "        return self.word_sense_proportions.copy()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:---------- Loading File ../embeddings/embeddings_1980.json ----------\n",
      "INFO:root:---------- Loading File ../embeddings/embeddings_for_senses.json ----------\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'word': 'please',\n 'props': [0.5709876543209876, 0.404320987654321, 0.024691358024691357]}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = Similarities()\n",
    "sim('please')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:---------- Loading File ../embeddings/embeddings_1980.json ----------\n",
      "INFO:root:---------- Loading File ../embeddings/embeddings_for_senses.json ----------\n"
     ]
    }
   ],
   "source": [
    "embeddings_examples, embeddings_senses = LoadingEmbeddings.load_files(\n",
    "            root_dir='../embeddings',\n",
    "            sense_embeddings_file=SENSES_FILE,\n",
    "            example_embeddings_file=EXAMPLES_FILE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def _search_word_sense(word:str):\n",
    "    for w in embeddings_senses:\n",
    "        if w[0]['word'] == word:\n",
    "            yield w\n",
    "\n",
    "def _cos_sim(vect_a:np.array, vect_b:np.array):\n",
    "    return (vect_a @ vect_b)/(norm(vect_a) * norm(vect_b))\n",
    "\n",
    "examples = np.array(embeddings_examples['right']['embeddings'])\n",
    "try:\n",
    "    senses = next(_search_word_sense('right'))\n",
    "except StopIteration:\n",
    "        raise ValueError(\n",
    "            'Word not in list'\n",
    "        )\n",
    "\n",
    "all_sims = []\n",
    "for embed in examples:\n",
    "    s_argmax =  np.argmax(list(_cos_sim(sens['embedding'], embed) for sens in senses))\n",
    "    all_sims.append(senses[s_argmax]['sense'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.2855564557707888,\n 0.20608381822199306,\n 0.1939309125727333,\n 0.11747808794284452,\n 0.11327981144582751,\n 0.08367091404581277]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "list(map(lambda x: x[1]/len(all_sims), Counter(all_sims).most_common()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
