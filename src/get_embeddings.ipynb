{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(year, targets):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('../articles_raw_data/news_' + str(year) + '.csv')\n",
    "    df = df['text']\n",
    "\n",
    "    bag = [item for sentence in df for item in sentence.split('.') if item != '']\n",
    "    bag_size = len(bag)\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "\n",
    "    for i in targets:\n",
    "        count = 0\n",
    "        for j in range(bag_size):\n",
    "\n",
    "            if count < 500:\n",
    "                sentence = bag[j].split()\n",
    "\n",
    "                if len(sentence) > 512:\n",
    "                    sentence = sentence[:512]\n",
    "\n",
    "\n",
    "                if i in sentence:\n",
    "                    sentences.append(bag[j])\n",
    "                    count += 1\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    \n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets():\n",
    "    words_file = open('../data/target_words/polysemous.txt', 'r')\n",
    "    targets = words_file.read().split('\\n')\n",
    "\n",
    "    return targets\n",
    "\n",
    "def get_sentences(year, targets):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('../articles_raw_data/news_' + str(year) + '.csv')\n",
    "    df = df['text']\n",
    "\n",
    "    bag = [item for sentence in df for item in sentence.split('.') if item != '']\n",
    "    bag_size = len(bag)\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "\n",
    "    for i in targets:\n",
    "        count = 0\n",
    "\n",
    "        for j in range(bag_size):\n",
    "\n",
    "            if count < 1000:\n",
    "                sentence = bag[j].split()\n",
    "\n",
    "                if len(sentence) > 512:\n",
    "                    sentence = sentence[:512]\n",
    "\n",
    "\n",
    "                if i in sentence:\n",
    "                    sentences.append(bag[j])\n",
    "                    count += 1\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "def infer_vector(doc:str):\n",
    "\n",
    "    marked_text = \"[CLS] \" + doc + \" [SEP]\"\n",
    "    tokens = bert_tokenizer.tokenize(marked_text)[:512]\n",
    "    idx = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "    segment_id = [1] * len(tokens)\n",
    "\n",
    "\n",
    "    tokens_tensor = torch.tensor([idx])\n",
    "    segments_tensors = torch.tensor([segment_id])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    hidden_states = hidden_states\n",
    "\n",
    "    return hidden_states[-2][0], tokens\n",
    "\n",
    "\n",
    "def get_embed(sentences, targets):\n",
    "\n",
    "\n",
    "    results = {k: {'word': k, 'sentence_number_index': [] , 'embeddings': []} for k in targets}\n",
    "\n",
    "    for i in range(len(sentences)): #len(sentences)\n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "\n",
    "        sentence = sentences[i].split()[:250]\n",
    "\n",
    "        for word in targets:\n",
    "\n",
    "            if word in sentence:\n",
    "                embeddings, tokens = infer_vector(sentences[i])\n",
    "\n",
    "                if word in tokens:\n",
    "                    index = tokens.index(word)\n",
    "                    embedding = embeddings[index].tolist()\n",
    "\n",
    "                    results[word]['sentence_number_index'].append([i, index])\n",
    "                    results[word]['embeddings'].append(embedding)\n",
    "                \n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(year):\n",
    "    print('getting targets ..............................')\n",
    "    targets = get_targets()\n",
    "    print('getting sentences ............................')\n",
    "    sentences = get_sentences(year= year, targets= targets)\n",
    "\n",
    "    print('saving sentences..............................')\n",
    "    file = open('../articles_raw_data/' + str(year) + '_sentences.txt','w') \n",
    "    \n",
    "    for item in sentences:\n",
    "        file.write(item+\"\\n\")\n",
    "    file.close()\n",
    "    print('getting embeddings for setences ..............')\n",
    "    results = get_embed(\n",
    "        sentences= sentences,\n",
    "        targets= targets\n",
    "    )\n",
    "    print('got embeddings  ..............................')\n",
    "    file = []\n",
    "\n",
    "    for word in targets:\n",
    "        file.append(results[word])\n",
    "    \n",
    "    print('saving embeddings ............................')\n",
    "    import json\n",
    "    with open('../embeddings/embeddings_' + str(year) + '.json', \"w\") as final:\n",
    "        json.dump(file, final, indent= 4)\n",
    "    \n",
    "    print(year, 'done ............................')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980\n",
      "getting targets ..............................\n",
      "getting sentences ............................\n",
      "saving sentences..............................\n",
      "getting embeddings for setences ..............\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "periods = [1980, 1982, 1985, 1987, 1989, 1990, 1992, 1995, 2000, 2001, 2002, 2003, 2005, 2008, 2009, 2010, 2012, 2013, 2015, 2016, 2017, 2018, 2019]\n",
    "\n",
    "for period in periods:\n",
    "    print(period)\n",
    "    get_all(period)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code:\n",
    "Please ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../articles_raw_data/news_' + str(year) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = [item for sentence in df for item in sentence.split('.') if item != '']\n",
    "bag_size = len(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660027"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandon',\n",
       " 'abandoned',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'abruptly',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accommodate',\n",
       " 'accompany',\n",
       " 'accord',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accurate',\n",
       " 'achievement',\n",
       " 'acid',\n",
       " 'acknowledge',\n",
       " 'acquaintance',\n",
       " 'acquire',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'acute',\n",
       " 'add',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'adjust',\n",
       " 'administration',\n",
       " 'administrator',\n",
       " 'admiral',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'advice',\n",
       " 'advocate',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affection',\n",
       " 'afford',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agree',\n",
       " 'agricultural',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airline',\n",
       " 'alarm',\n",
       " 'alert',\n",
       " 'alien',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'alley',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'ally',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'aloud',\n",
       " 'already',\n",
       " 'alternative',\n",
       " 'always',\n",
       " 'amateur',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amusement',\n",
       " 'analysis',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'anguish',\n",
       " 'animal',\n",
       " 'animated',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'antique',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anyone',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apology',\n",
       " 'apparatus',\n",
       " 'apparent',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'apple',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciation',\n",
       " 'apprehension',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approve',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'arc',\n",
       " 'arch',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " 'ardent',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arise',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arrive',\n",
       " 'art',\n",
       " 'article',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'ash',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'aspect',\n",
       " 'assault',\n",
       " 'assembly',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'associate',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assumption',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'at',\n",
       " 'athletic',\n",
       " 'atmosphere',\n",
       " 'atop',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attendance',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'audience',\n",
       " 'august',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awful',\n",
       " 'awkward',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backward',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'baggage',\n",
       " 'balance',\n",
       " 'balcony',\n",
       " 'bald',\n",
       " 'ball',\n",
       " 'ballot',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'banking',\n",
       " 'banner',\n",
       " 'bar',\n",
       " 'bare',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'bark',\n",
       " 'barn',\n",
       " 'barrel',\n",
       " 'base',\n",
       " 'basic',\n",
       " 'basin',\n",
       " 'basket',\n",
       " 'bastard',\n",
       " 'bath',\n",
       " 'battered',\n",
       " 'battle',\n",
       " 'bay',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beam',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'bearing',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'beef',\n",
       " 'before',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beloved',\n",
       " 'below',\n",
       " 'belt',\n",
       " 'bench',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'betray',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'billy',\n",
       " 'bind',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'bishop',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'bitterly',\n",
       " 'bitterness',\n",
       " 'black',\n",
       " 'blade',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'bloom',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blunt',\n",
       " 'blush',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bodily',\n",
       " 'body',\n",
       " 'boiling',\n",
       " 'bold',\n",
       " 'bolt',\n",
       " 'bomb',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'book',\n",
       " 'boom',\n",
       " 'boost',\n",
       " 'booth',\n",
       " 'border',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'borrow',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brass',\n",
       " 'brave',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathing',\n",
       " 'breed',\n",
       " 'breeze',\n",
       " 'brick',\n",
       " 'bridge',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brightly',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'brisk',\n",
       " 'broad',\n",
       " 'broadcast',\n",
       " 'broadly',\n",
       " 'bronze',\n",
       " 'brother',\n",
       " 'brow',\n",
       " 'brown',\n",
       " 'brush',\n",
       " 'buck',\n",
       " 'bucket',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buffalo',\n",
       " 'build',\n",
       " 'building',\n",
       " 'bulk',\n",
       " 'bull',\n",
       " 'bullet',\n",
       " 'bunch',\n",
       " 'bundle',\n",
       " 'burden',\n",
       " 'bureau',\n",
       " 'burn',\n",
       " 'burst',\n",
       " 'bury',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'bust',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butter',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cab',\n",
       " 'cabin',\n",
       " 'cabinet',\n",
       " 'cable',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'call',\n",
       " 'calm',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'can',\n",
       " 'canal',\n",
       " 'cancer',\n",
       " 'candle',\n",
       " 'candy',\n",
       " 'cane',\n",
       " 'cannon',\n",
       " 'canvas',\n",
       " 'cap',\n",
       " 'capable',\n",
       " 'capacity',\n",
       " 'cape',\n",
       " 'capital',\n",
       " 'captain',\n",
       " 'capture',\n",
       " 'card',\n",
       " 'cardboard',\n",
       " 'care',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'carpet',\n",
       " 'carriage',\n",
       " 'carrier',\n",
       " 'carry',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'castle',\n",
       " 'casual',\n",
       " 'casually',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'category',\n",
       " 'catholic',\n",
       " 'cattle',\n",
       " 'cause',\n",
       " 'caution',\n",
       " 'cave',\n",
       " 'ceiling',\n",
       " 'celebrate',\n",
       " 'cell',\n",
       " 'cellar',\n",
       " 'cement',\n",
       " 'cent',\n",
       " 'central',\n",
       " 'centre',\n",
       " 'century',\n",
       " 'ceremony',\n",
       " 'certain',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challenge',\n",
       " 'chamber',\n",
       " 'champion',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'channel',\n",
       " 'chapel',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'characteristic',\n",
       " 'charge',\n",
       " 'charity',\n",
       " 'charlie',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'charter',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'cheek',\n",
       " 'chemical',\n",
       " 'chest',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'chill',\n",
       " 'chin',\n",
       " 'china',\n",
       " 'choice',\n",
       " 'chorus',\n",
       " 'church',\n",
       " 'circle',\n",
       " 'circuit',\n",
       " 'circular',\n",
       " 'circulation',\n",
       " 'circumstance',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'civilian',\n",
       " 'clad',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classical',\n",
       " 'classified',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearing',\n",
       " 'clerk',\n",
       " 'clever',\n",
       " 'client',\n",
       " 'climax',\n",
       " 'climb',\n",
       " 'clinic',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closely',\n",
       " 'closer',\n",
       " 'closet',\n",
       " 'cloth',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clown',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'coach',\n",
       " 'coal',\n",
       " 'coarse',\n",
       " 'coast',\n",
       " 'coat',\n",
       " 'cocktail',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'coin',\n",
       " 'cold',\n",
       " 'collapse',\n",
       " 'collar',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'collective',\n",
       " 'college',\n",
       " 'colonial',\n",
       " 'colony',\n",
       " 'column',\n",
       " 'combat',\n",
       " 'combination',\n",
       " 'combine',\n",
       " 'come',\n",
       " 'comedy',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comfortably',\n",
       " 'comic',\n",
       " 'command',\n",
       " 'commander',\n",
       " 'comment',\n",
       " 'commerce',\n",
       " 'commercial',\n",
       " 'commission',\n",
       " 'commit',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'common',\n",
       " 'commonplace',\n",
       " 'communicate',\n",
       " 'communication',\n",
       " 'communist',\n",
       " 'community',\n",
       " 'compact',\n",
       " 'companion',\n",
       " 'company',\n",
       " 'comparative',\n",
       " 'compare',\n",
       " 'compensation',\n",
       " 'competitive',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'complex',\n",
       " 'complexion',\n",
       " 'complicated',\n",
       " 'composition',\n",
       " 'compound',\n",
       " 'comprehend',\n",
       " 'comprehensive',\n",
       " 'compromise',\n",
       " 'conceive',\n",
       " 'concentrate',\n",
       " 'concentration',\n",
       " 'conception',\n",
       " 'concern',\n",
       " 'concert',\n",
       " 'conclude',\n",
       " 'conclusion',\n",
       " 'concrete',\n",
       " 'condition',\n",
       " 'conduct',\n",
       " 'conference',\n",
       " 'confession',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'confirm',\n",
       " 'confirmation',\n",
       " 'conflict',\n",
       " 'confused',\n",
       " 'confusion',\n",
       " 'congress',\n",
       " 'congressional',\n",
       " 'connection',\n",
       " 'conscious',\n",
       " 'consciousness',\n",
       " 'consent',\n",
       " 'consequence',\n",
       " 'conservative',\n",
       " 'consider',\n",
       " 'consideration',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'constant',\n",
       " 'constitute',\n",
       " 'constitution',\n",
       " 'constitutional',\n",
       " 'construction',\n",
       " 'consult',\n",
       " 'consultant',\n",
       " 'consulting',\n",
       " 'consumption',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'contemporary',\n",
       " 'contend',\n",
       " 'content',\n",
       " 'contention',\n",
       " 'contest',\n",
       " 'continent',\n",
       " 'continental',\n",
       " 'continually',\n",
       " 'continue',\n",
       " 'contract',\n",
       " 'contrary',\n",
       " 'contrast',\n",
       " 'control',\n",
       " 'controlled',\n",
       " 'convenience',\n",
       " 'convention',\n",
       " 'conventional',\n",
       " 'convert',\n",
       " 'convey',\n",
       " 'conviction',\n",
       " 'cook',\n",
       " 'cooked',\n",
       " 'cool',\n",
       " 'cop',\n",
       " 'cope',\n",
       " 'copper',\n",
       " 'copy',\n",
       " 'cord',\n",
       " 'core',\n",
       " 'corn',\n",
       " 'corner',\n",
       " 'corporate',\n",
       " 'corporation',\n",
       " 'corpse',\n",
       " 'correct',\n",
       " 'correspondence',\n",
       " 'correspondent',\n",
       " 'corrupt',\n",
       " 'corruption',\n",
       " 'cost',\n",
       " 'costume',\n",
       " 'cottage',\n",
       " 'cotton',\n",
       " 'couch',\n",
       " 'counsel',\n",
       " 'counter',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'court',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'cow',\n",
       " 'crack',\n",
       " 'cracked',\n",
       " 'craft',\n",
       " 'crash',\n",
       " 'crawl',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'create',\n",
       " 'creation',\n",
       " 'creative',\n",
       " 'creature',\n",
       " 'credit',\n",
       " 'creek',\n",
       " 'crew',\n",
       " 'criminal',\n",
       " 'crimson',\n",
       " 'crisp',\n",
       " 'critic',\n",
       " 'critical',\n",
       " 'criticism',\n",
       " 'crooked',\n",
       " 'crop',\n",
       " 'cross',\n",
       " 'crossing',\n",
       " 'crowd',\n",
       " 'crown',\n",
       " 'crude',\n",
       " 'cruel',\n",
       " 'crushed',\n",
       " 'cry',\n",
       " 'crystal',\n",
       " 'cultural',\n",
       " 'culture',\n",
       " 'cunning',\n",
       " 'cup',\n",
       " 'curb',\n",
       " 'cure',\n",
       " 'curiosity',\n",
       " 'curious',\n",
       " 'curiously',\n",
       " 'currency',\n",
       " 'current',\n",
       " 'curse',\n",
       " 'curtain',\n",
       " 'curve',\n",
       " 'custom',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cutting',\n",
       " 'cycle',\n",
       " 'cynical',\n",
       " 'daily',\n",
       " 'dam',\n",
       " 'damage',\n",
       " 'damn',\n",
       " 'damned',\n",
       " 'damp',\n",
       " 'dan',\n",
       " 'dance',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'darkness',\n",
       " 'darling',\n",
       " 'dash',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'dawn',\n",
       " 'day',\n",
       " 'daylight',\n",
       " 'dead',\n",
       " 'deadly',\n",
       " 'deal',\n",
       " 'dealer',\n",
       " 'dean',\n",
       " 'dear',\n",
       " 'debate',\n",
       " 'decade',\n",
       " 'decay',\n",
       " 'decent',\n",
       " 'decidedly',\n",
       " 'decisive',\n",
       " 'deck',\n",
       " 'declaration',\n",
       " 'declare',\n",
       " 'decline',\n",
       " 'decrease',\n",
       " 'dedicated',\n",
       " 'deed',\n",
       " 'deep',\n",
       " 'deeply',\n",
       " 'defeat',\n",
       " 'defend',\n",
       " 'defensive',\n",
       " 'define',\n",
       " 'definition',\n",
       " 'degree',\n",
       " 'delay',\n",
       " 'delegate',\n",
       " 'delegation',\n",
       " 'deliberate',\n",
       " 'deliberately',\n",
       " 'delicate',\n",
       " 'delight',\n",
       " 'deliver',\n",
       " 'delivery',\n",
       " 'demand',\n",
       " 'democrat',\n",
       " 'democratic',\n",
       " 'demonstrate',\n",
       " 'demonstration',\n",
       " 'den',\n",
       " 'dense',\n",
       " 'deny',\n",
       " 'depend',\n",
       " 'dependent',\n",
       " 'depressed',\n",
       " 'depression',\n",
       " 'depth',\n",
       " 'descent',\n",
       " 'describe',\n",
       " 'description',\n",
       " 'desert',\n",
       " 'design',\n",
       " 'desirable',\n",
       " 'desire',\n",
       " 'desk',\n",
       " 'despair',\n",
       " 'desperate',\n",
       " 'despite',\n",
       " 'destruction',\n",
       " 'detail',\n",
       " 'determination',\n",
       " 'determine',\n",
       " 'develop',\n",
       " 'developing',\n",
       " 'development',\n",
       " 'device',\n",
       " 'devil',\n",
       " 'devote',\n",
       " 'dialogue',\n",
       " 'diamond',\n",
       " 'dick',\n",
       " 'diet',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'differently',\n",
       " 'dig',\n",
       " 'dignity',\n",
       " 'dim',\n",
       " 'dimly',\n",
       " 'diplomatic',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'dirt',\n",
       " 'dirty',\n",
       " 'discharge',\n",
       " 'discipline',\n",
       " 'discourse',\n",
       " 'discover',\n",
       " 'discovery',\n",
       " 'discretion',\n",
       " 'discrimination',\n",
       " 'disgrace',\n",
       " 'disgust',\n",
       " 'dish',\n",
       " 'dislike',\n",
       " 'dismay',\n",
       " 'display',\n",
       " 'disposition',\n",
       " 'dispute',\n",
       " 'dissolve',\n",
       " 'distance',\n",
       " 'distant',\n",
       " 'distinct',\n",
       " 'distinction',\n",
       " 'distinguish',\n",
       " 'distress',\n",
       " 'distribution',\n",
       " 'district',\n",
       " 'disturb',\n",
       " 'divide',\n",
       " 'divine',\n",
       " 'division',\n",
       " 'divorce',\n",
       " 'do',\n",
       " 'doctor',\n",
       " 'document',\n",
       " 'dog',\n",
       " 'doll',\n",
       " 'domain',\n",
       " 'domestic',\n",
       " 'dominant',\n",
       " 'don',\n",
       " 'door',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'down',\n",
       " 'downstairs',\n",
       " 'downtown',\n",
       " 'downward',\n",
       " 'dozen',\n",
       " 'draft',\n",
       " 'drag',\n",
       " 'drain',\n",
       " 'drama',\n",
       " 'dramatic',\n",
       " 'dramatically',\n",
       " 'draw',\n",
       " 'drawer',\n",
       " 'drawing',\n",
       " 'dread',\n",
       " 'dreadful',\n",
       " 'dream',\n",
       " 'dressing',\n",
       " 'drift',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'driver',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'drug',\n",
       " 'dry',\n",
       " 'duck',\n",
       " 'due',\n",
       " 'duke',\n",
       " 'dull',\n",
       " 'dumb',\n",
       " 'dusk',\n",
       " 'dust',\n",
       " 'dutch',\n",
       " 'dwell',\n",
       " 'each',\n",
       " 'eagle',\n",
       " 'ear',\n",
       " 'early',\n",
       " 'earnest',\n",
       " 'earth',\n",
       " 'ease',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'eastern',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'echo',\n",
       " 'economic',\n",
       " 'economically',\n",
       " 'economics',\n",
       " 'economy',\n",
       " 'edge',\n",
       " 'edition',\n",
       " 'editor',\n",
       " 'editorial',\n",
       " 'education',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'efficient',\n",
       " 'effort',\n",
       " 'egg',\n",
       " 'eighteenth',\n",
       " 'eighth',\n",
       " 'either',\n",
       " 'elaborate',\n",
       " 'elbow',\n",
       " 'elder',\n",
       " 'elect',\n",
       " 'electric',\n",
       " 'electrical',\n",
       " 'electricity',\n",
       " 'electronic',\n",
       " 'elegant',\n",
       " 'element',\n",
       " 'elementary',\n",
       " 'elevation',\n",
       " 'elevator',\n",
       " 'eliminate',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'embassy',\n",
       " 'embrace',\n",
       " 'emerge',\n",
       " 'eminent',\n",
       " 'emphasis',\n",
       " 'emphasize',\n",
       " 'empire',\n",
       " 'employ',\n",
       " 'employment',\n",
       " 'enable',\n",
       " 'encounter',\n",
       " 'end',\n",
       " 'endurance',\n",
       " 'endure',\n",
       " 'energy',\n",
       " 'engage',\n",
       " 'engagement',\n",
       " 'engine',\n",
       " 'engineer',\n",
       " 'engineering',\n",
       " 'enjoy',\n",
       " 'enjoyment',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'enterprise',\n",
       " 'entertain',\n",
       " 'entire',\n",
       " 'entrance',\n",
       " 'entry',\n",
       " 'envelope',\n",
       " 'environment',\n",
       " 'envy',\n",
       " 'episode',\n",
       " 'equal',\n",
       " 'equality',\n",
       " 'equivalent',\n",
       " 'erect',\n",
       " 'escape',\n",
       " 'especially',\n",
       " 'essence',\n",
       " 'essential',\n",
       " 'establish',\n",
       " 'establishment',\n",
       " 'estate',\n",
       " 'esteem',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_file = open('../data/target_words/polysemous.txt', 'r')\n",
    "targets = words_file.read().split('\\n')\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3220"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abandon\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bag_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(i)\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(bag_size):\n\u001b[1;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m count \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[1;32m     10\u001b[0m         sentence \u001b[39m=\u001b[39m bag[j]\u001b[39m.\u001b[39msplit()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bag_size' is not defined"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "\n",
    "for i in targets:\n",
    "    count = 0\n",
    "    print(i)\n",
    "    for j in range(bag_size):\n",
    "\n",
    "        if count < 1000:\n",
    "            sentence = bag[j].split()\n",
    "\n",
    "            if len(sentence) > 512:\n",
    "                sentence = sentence[:512]\n",
    "\n",
    "\n",
    "            if i in sentence:\n",
    "                sentences.append(bag[j])\n",
    "                count += 1\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../articles_raw_data/' + str(year) + '_sentences.txt','w') \n",
    "\n",
    "for item in sentences:\n",
    "\tfile.write(item+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_vector(doc:str):\n",
    "\n",
    "    marked_text = \"[CLS] \" + doc + \" [SEP]\"\n",
    "    tokens = bert_tokenizer.tokenize(marked_text)[:512]\n",
    "    idx = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "    segment_id = [1] * len(tokens)\n",
    "\n",
    "\n",
    "    tokens_tensor = torch.tensor([idx])\n",
    "    segments_tensors = torch.tensor([segment_id])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    hidden_states = hidden_states\n",
    "\n",
    "    return hidden_states[-2][0], tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n"
     ]
    }
   ],
   "source": [
    "results = {k: {'word': k, 'sentence_number_index': [] , 'embeddings': []} for k in targets}\n",
    "\n",
    "for i in range(len(sentences)): #len(sentences)\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "    sentence = sentences[i].split()[:250]\n",
    "\n",
    "    for word in targets:\n",
    "\n",
    "        if word in sentence:\n",
    "            embeddings, tokens = infer_vector(sentences[i])\n",
    "\n",
    "            index = tokens.index(word)\n",
    "            embedding = embeddings[index].tolist()\n",
    "\n",
    "            results[word]['sentence_number_index'].append([i, index])\n",
    "            results[word]['embeddings'].append(embedding)\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = []\n",
    "\n",
    "for word in targets:\n",
    "    results[word]['word'] = word\n",
    "    file.append(results[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../embeddings/embeddings_' + str(year) + '.json', \"w\") as final:\n",
    "    json.dump(file, final, indent= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../embeddings/embeddings_2015.json\n"
     ]
    }
   ],
   "source": [
    "print('../embeddings/embeddings_' + str(year) + '.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imenepy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a504093cd48dbf41332b0076d682ce93e05d52a892a597f2a787966ee958626a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
