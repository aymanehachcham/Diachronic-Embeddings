{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/news_1980.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[39m=\u001B[39m pd\u001B[39m.\u001B[39;49mread_csv(\u001B[39m'\u001B[39;49m\u001B[39m../data/news_1980.csv\u001B[39;49m\u001B[39m'\u001B[39;49m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m     \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[39m=\u001B[39m new_arg_value\n\u001B[0;32m--> 211\u001B[0m \u001B[39mreturn\u001B[39;00m func(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mlen\u001B[39m(args) \u001B[39m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[39m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[39m.\u001B[39mformat(arguments\u001B[39m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[39mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[39m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[39mreturn\u001B[39;00m func(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[39m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    946\u001B[0m     defaults\u001B[39m=\u001B[39m{\u001B[39m\"\u001B[39m\u001B[39mdelimiter\u001B[39m\u001B[39m\"\u001B[39m: \u001B[39m\"\u001B[39m\u001B[39m,\u001B[39m\u001B[39m\"\u001B[39m},\n\u001B[1;32m    947\u001B[0m )\n\u001B[1;32m    948\u001B[0m kwds\u001B[39m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 950\u001B[0m \u001B[39mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    602\u001B[0m _validate_names(kwds\u001B[39m.\u001B[39mget(\u001B[39m\"\u001B[39m\u001B[39mnames\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39mNone\u001B[39;00m))\n\u001B[1;32m    604\u001B[0m \u001B[39m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 605\u001B[0m parser \u001B[39m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwds)\n\u001B[1;32m    607\u001B[0m \u001B[39mif\u001B[39;00m chunksize \u001B[39mor\u001B[39;00m iterator:\n\u001B[1;32m    608\u001B[0m     \u001B[39mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1439\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39moptions[\u001B[39m\"\u001B[39m\u001B[39mhas_index_names\u001B[39m\u001B[39m\"\u001B[39m] \u001B[39m=\u001B[39m kwds[\u001B[39m\"\u001B[39m\u001B[39mhas_index_names\u001B[39m\u001B[39m\"\u001B[39m]\n\u001B[1;32m   1441\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandles: IOHandles \u001B[39m|\u001B[39m \u001B[39mNone\u001B[39;00m \u001B[39m=\u001B[39m \u001B[39mNone\u001B[39;00m\n\u001B[0;32m-> 1442\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_engine \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_make_engine(f, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mengine)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1733\u001B[0m     \u001B[39mif\u001B[39;00m \u001B[39m\"\u001B[39m\u001B[39mb\u001B[39m\u001B[39m\"\u001B[39m \u001B[39mnot\u001B[39;00m \u001B[39min\u001B[39;00m mode:\n\u001B[1;32m   1734\u001B[0m         mode \u001B[39m+\u001B[39m\u001B[39m=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mb\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m-> 1735\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandles \u001B[39m=\u001B[39m get_handle(\n\u001B[1;32m   1736\u001B[0m     f,\n\u001B[1;32m   1737\u001B[0m     mode,\n\u001B[1;32m   1738\u001B[0m     encoding\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49moptions\u001B[39m.\u001B[39;49mget(\u001B[39m\"\u001B[39;49m\u001B[39mencoding\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39mNone\u001B[39;49;00m),\n\u001B[1;32m   1739\u001B[0m     compression\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49moptions\u001B[39m.\u001B[39;49mget(\u001B[39m\"\u001B[39;49m\u001B[39mcompression\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39mNone\u001B[39;49;00m),\n\u001B[1;32m   1740\u001B[0m     memory_map\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49moptions\u001B[39m.\u001B[39;49mget(\u001B[39m\"\u001B[39;49m\u001B[39mmemory_map\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39mFalse\u001B[39;49;00m),\n\u001B[1;32m   1741\u001B[0m     is_text\u001B[39m=\u001B[39;49mis_text,\n\u001B[1;32m   1742\u001B[0m     errors\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49moptions\u001B[39m.\u001B[39;49mget(\u001B[39m\"\u001B[39;49m\u001B[39mencoding_errors\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39m\"\u001B[39;49m\u001B[39mstrict\u001B[39;49m\u001B[39m\"\u001B[39;49m),\n\u001B[1;32m   1743\u001B[0m     storage_options\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49moptions\u001B[39m.\u001B[39;49mget(\u001B[39m\"\u001B[39;49m\u001B[39mstorage_options\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39mNone\u001B[39;49;00m),\n\u001B[1;32m   1744\u001B[0m )\n\u001B[1;32m   1745\u001B[0m \u001B[39massert\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandles \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m f \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandles\u001B[39m.\u001B[39mhandle\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/pandas/io/common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    851\u001B[0m \u001B[39melif\u001B[39;00m \u001B[39misinstance\u001B[39m(handle, \u001B[39mstr\u001B[39m):\n\u001B[1;32m    852\u001B[0m     \u001B[39m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    853\u001B[0m     \u001B[39m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    854\u001B[0m     \u001B[39mif\u001B[39;00m ioargs\u001B[39m.\u001B[39mencoding \u001B[39mand\u001B[39;00m \u001B[39m\"\u001B[39m\u001B[39mb\u001B[39m\u001B[39m\"\u001B[39m \u001B[39mnot\u001B[39;00m \u001B[39min\u001B[39;00m ioargs\u001B[39m.\u001B[39mmode:\n\u001B[1;32m    855\u001B[0m         \u001B[39m# Encoding\u001B[39;00m\n\u001B[0;32m--> 856\u001B[0m         handle \u001B[39m=\u001B[39m \u001B[39mopen\u001B[39;49m(\n\u001B[1;32m    857\u001B[0m             handle,\n\u001B[1;32m    858\u001B[0m             ioargs\u001B[39m.\u001B[39;49mmode,\n\u001B[1;32m    859\u001B[0m             encoding\u001B[39m=\u001B[39;49mioargs\u001B[39m.\u001B[39;49mencoding,\n\u001B[1;32m    860\u001B[0m             errors\u001B[39m=\u001B[39;49merrors,\n\u001B[1;32m    861\u001B[0m             newline\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39m\"\u001B[39;49m,\n\u001B[1;32m    862\u001B[0m         )\n\u001B[1;32m    863\u001B[0m     \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    864\u001B[0m         \u001B[39m# Binary mode\u001B[39;00m\n\u001B[1;32m    865\u001B[0m         handle \u001B[39m=\u001B[39m \u001B[39mopen\u001B[39m(handle, ioargs\u001B[39m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/news_1980.csv'"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> 706a074a6ed586bc1c4d95715344fdf423f09a21
   "source": [
    "df = pd.read_csv('../articles_raw_data/news_1980.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = [item for sentence in df for item in sentence.split('.') if item != '']\n",
    "bag_size = len(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426406"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['state', 'right', 'around', 'black', 'force', 'interest', 'support', 'charge', 'please']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "right\n",
<<<<<<< HEAD
      "point\n",
      "since\n",
      "world\n",
      "second\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [17], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[39mfor\u001B[39;00m j \u001B[39min\u001B[39;00m \u001B[39mrange\u001B[39m(bag_size):\n\u001B[1;32m      7\u001B[0m     sentence \u001B[39m=\u001B[39m bag[j]\u001B[39m.\u001B[39msplit()\n\u001B[0;32m----> 9\u001B[0m     \u001B[39mif\u001B[39;00m i \u001B[39min\u001B[39;00m sentence[:\u001B[39m512\u001B[39;49m]:\n\u001B[1;32m     10\u001B[0m         sentences\u001B[39m.\u001B[39mappend(bag[j])\n\u001B[1;32m     11\u001B[0m     \u001B[39melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
=======
      "around\n",
      "black\n",
      "force\n",
      "interest\n",
      "support\n",
      "charge\n",
<<<<<<< HEAD
      "84609\n"
>>>>>>> 706a074a6ed586bc1c4d95715344fdf423f09a21
=======
      "please\n",
      "92096\n"
>>>>>>> 1479b2c9f404e7e1e7da36b971b1b5df8722d971
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "\n",
    "for i in targets:\n",
    "    print(i)\n",
    "    for j in range(bag_size):\n",
    "        sentence = bag[j].split()\n",
    "\n",
    "        if len(sentence) > 512:\n",
    "            sentence = sentence[:512]\n",
    "\n",
    "\n",
    "        if i in sentence:\n",
    "            sentences.append(bag[j])\n",
    "        else:\n",
    "            continue\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../articles_raw_data/1980_sentences.txt','w')\n",
    "\n",
    "for item in sentences:\n",
    "\tfile.write(item+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_vector(doc:str):\n",
    "\n",
    "    marked_text = \"[CLS] \" + doc + \" [SEP]\"\n",
    "    tokens = bert_tokenizer.tokenize(marked_text)[:512]\n",
    "    idx = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "    segment_id = [1] * len(tokens)\n",
    "\n",
    "\n",
    "    tokens_tensor = torch.tensor([idx])\n",
    "    segments_tensors = torch.tensor([segment_id])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    hidden_states = hidden_states\n",
    "\n",
    "    return hidden_states[-2][0], tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92096"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "results = {k: {'sentence_number_index': [] , 'embeddings': []} for k in targets}\n",
    "\n",
    "for i in range(len(sentences)): #len(sentences)\n",
    "    if i%10000 == 0:\n",
    "        print(i)\n",
    "\n",
    "    sentence = sentences[i].split()\n",
    "\n",
    "    for word in targets:\n",
    "\n",
    "        if word in sentence:\n",
    "            embeddings, tokens = infer_vector(sentences[i])\n",
    "\n",
    "            index = tokens.index(word)\n",
    "            embedding = embeddings[index].tolist()\n",
    "\n",
    "            results[word]['sentence_number_index'].append([i, index])\n",
    "            results[word]['embeddings'].append(embedding)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../embeddings/embeddings_1980.json', 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [15], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[39mfor\u001B[39;00m i \u001B[39min\u001B[39;00m \u001B[39mrange\u001B[39m(\u001B[39mlen\u001B[39m(sentences)):\n\u001B[0;32m----> 2\u001B[0m     embedding \u001B[39m=\u001B[39m infer_vector(sentences[i])\n\u001B[1;32m      3\u001B[0m \u001B[39mprint\u001B[39m(embedding\u001B[39m.\u001B[39msize())\n",
      "Cell \u001B[0;32mIn [14], line 13\u001B[0m, in \u001B[0;36minfer_vector\u001B[0;34m(doc)\u001B[0m\n\u001B[1;32m     10\u001B[0m segments_tensors \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mtensor([segment_id])\n\u001B[1;32m     12\u001B[0m \u001B[39mwith\u001B[39;00m torch\u001B[39m.\u001B[39mno_grad():\n\u001B[0;32m---> 13\u001B[0m     outputs \u001B[39m=\u001B[39m model(tokens_tensor, segments_tensors)\n\u001B[1;32m     14\u001B[0m     hidden_states \u001B[39m=\u001B[39m outputs[\u001B[39m2\u001B[39m]\n\u001B[1;32m     16\u001B[0m hidden_states \u001B[39m=\u001B[39m hidden_states\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1131\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1019\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1010\u001B[0m head_mask \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mget_head_mask(head_mask, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mconfig\u001B[39m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m   1012\u001B[0m embedding_output \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39membeddings(\n\u001B[1;32m   1013\u001B[0m     input_ids\u001B[39m=\u001B[39minput_ids,\n\u001B[1;32m   1014\u001B[0m     position_ids\u001B[39m=\u001B[39mposition_ids,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1017\u001B[0m     past_key_values_length\u001B[39m=\u001B[39mpast_key_values_length,\n\u001B[1;32m   1018\u001B[0m )\n\u001B[0;32m-> 1019\u001B[0m encoder_outputs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mencoder(\n\u001B[1;32m   1020\u001B[0m     embedding_output,\n\u001B[1;32m   1021\u001B[0m     attention_mask\u001B[39m=\u001B[39;49mextended_attention_mask,\n\u001B[1;32m   1022\u001B[0m     head_mask\u001B[39m=\u001B[39;49mhead_mask,\n\u001B[1;32m   1023\u001B[0m     encoder_hidden_states\u001B[39m=\u001B[39;49mencoder_hidden_states,\n\u001B[1;32m   1024\u001B[0m     encoder_attention_mask\u001B[39m=\u001B[39;49mencoder_extended_attention_mask,\n\u001B[1;32m   1025\u001B[0m     past_key_values\u001B[39m=\u001B[39;49mpast_key_values,\n\u001B[1;32m   1026\u001B[0m     use_cache\u001B[39m=\u001B[39;49muse_cache,\n\u001B[1;32m   1027\u001B[0m     output_attentions\u001B[39m=\u001B[39;49moutput_attentions,\n\u001B[1;32m   1028\u001B[0m     output_hidden_states\u001B[39m=\u001B[39;49moutput_hidden_states,\n\u001B[1;32m   1029\u001B[0m     return_dict\u001B[39m=\u001B[39;49mreturn_dict,\n\u001B[1;32m   1030\u001B[0m )\n\u001B[1;32m   1031\u001B[0m sequence_output \u001B[39m=\u001B[39m encoder_outputs[\u001B[39m0\u001B[39m]\n\u001B[1;32m   1032\u001B[0m pooled_output \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mpooler(sequence_output) \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mpooler \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m \u001B[39melse\u001B[39;00m \u001B[39mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1131\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:609\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    600\u001B[0m     layer_outputs \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mutils\u001B[39m.\u001B[39mcheckpoint\u001B[39m.\u001B[39mcheckpoint(\n\u001B[1;32m    601\u001B[0m         create_custom_forward(layer_module),\n\u001B[1;32m    602\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    606\u001B[0m         encoder_attention_mask,\n\u001B[1;32m    607\u001B[0m     )\n\u001B[1;32m    608\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m--> 609\u001B[0m     layer_outputs \u001B[39m=\u001B[39m layer_module(\n\u001B[1;32m    610\u001B[0m         hidden_states,\n\u001B[1;32m    611\u001B[0m         attention_mask,\n\u001B[1;32m    612\u001B[0m         layer_head_mask,\n\u001B[1;32m    613\u001B[0m         encoder_hidden_states,\n\u001B[1;32m    614\u001B[0m         encoder_attention_mask,\n\u001B[1;32m    615\u001B[0m         past_key_value,\n\u001B[1;32m    616\u001B[0m         output_attentions,\n\u001B[1;32m    617\u001B[0m     )\n\u001B[1;32m    619\u001B[0m hidden_states \u001B[39m=\u001B[39m layer_outputs[\u001B[39m0\u001B[39m]\n\u001B[1;32m    620\u001B[0m \u001B[39mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1131\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:495\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    483\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\n\u001B[1;32m    484\u001B[0m     \u001B[39mself\u001B[39m,\n\u001B[1;32m    485\u001B[0m     hidden_states: torch\u001B[39m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    492\u001B[0m ) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m Tuple[torch\u001B[39m.\u001B[39mTensor]:\n\u001B[1;32m    493\u001B[0m     \u001B[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[1;32m    494\u001B[0m     self_attn_past_key_value \u001B[39m=\u001B[39m past_key_value[:\u001B[39m2\u001B[39m] \u001B[39mif\u001B[39;00m past_key_value \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m \u001B[39melse\u001B[39;00m \u001B[39mNone\u001B[39;00m\n\u001B[0;32m--> 495\u001B[0m     self_attention_outputs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mattention(\n\u001B[1;32m    496\u001B[0m         hidden_states,\n\u001B[1;32m    497\u001B[0m         attention_mask,\n\u001B[1;32m    498\u001B[0m         head_mask,\n\u001B[1;32m    499\u001B[0m         output_attentions\u001B[39m=\u001B[39;49moutput_attentions,\n\u001B[1;32m    500\u001B[0m         past_key_value\u001B[39m=\u001B[39;49mself_attn_past_key_value,\n\u001B[1;32m    501\u001B[0m     )\n\u001B[1;32m    502\u001B[0m     attention_output \u001B[39m=\u001B[39m self_attention_outputs[\u001B[39m0\u001B[39m]\n\u001B[1;32m    504\u001B[0m     \u001B[39m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1131\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:425\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    415\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\n\u001B[1;32m    416\u001B[0m     \u001B[39mself\u001B[39m,\n\u001B[1;32m    417\u001B[0m     hidden_states: torch\u001B[39m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    423\u001B[0m     output_attentions: Optional[\u001B[39mbool\u001B[39m] \u001B[39m=\u001B[39m \u001B[39mFalse\u001B[39;00m,\n\u001B[1;32m    424\u001B[0m ) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m Tuple[torch\u001B[39m.\u001B[39mTensor]:\n\u001B[0;32m--> 425\u001B[0m     self_outputs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mself(\n\u001B[1;32m    426\u001B[0m         hidden_states,\n\u001B[1;32m    427\u001B[0m         attention_mask,\n\u001B[1;32m    428\u001B[0m         head_mask,\n\u001B[1;32m    429\u001B[0m         encoder_hidden_states,\n\u001B[1;32m    430\u001B[0m         encoder_attention_mask,\n\u001B[1;32m    431\u001B[0m         past_key_value,\n\u001B[1;32m    432\u001B[0m         output_attentions,\n\u001B[1;32m    433\u001B[0m     )\n\u001B[1;32m    434\u001B[0m     attention_output \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39moutput(self_outputs[\u001B[39m0\u001B[39m], hidden_states)\n\u001B[1;32m    435\u001B[0m     outputs \u001B[39m=\u001B[39m (attention_output,) \u001B[39m+\u001B[39m self_outputs[\u001B[39m1\u001B[39m:]  \u001B[39m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1131\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/imenepy/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:307\u001B[0m, in \u001B[0;36mBertSelfAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    306\u001B[0m     key_layer \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtranspose_for_scores(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mkey(hidden_states))\n\u001B[0;32m--> 307\u001B[0m     value_layer \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtranspose_for_scores(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mvalue(hidden_states))\n\u001B[1;32m    309\u001B[0m query_layer \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtranspose_for_scores(mixed_query_layer)\n\u001B[1;32m    311\u001B[0m use_cache \u001B[39m=\u001B[39m past_key_value \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    embedding = infer_vector(sentences[i])\n",
    "print(embedding.size())"
   ]
=======
>>>>>>> 706a074a6ed586bc1c4d95715344fdf423f09a21
=======
>>>>>>> 1479b2c9f404e7e1e7da36b971b1b5df8722d971
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imenepy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a504093cd48dbf41332b0076d682ce93e05d52a892a597f2a787966ee958626a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
